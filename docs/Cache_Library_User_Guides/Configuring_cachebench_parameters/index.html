<!doctype html>
<html class="docs-version-current" lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.6">
<link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="CacheLib Blog RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="CacheLib Blog Atom Feed">
<link rel="search" type="application/opensearchdescription+xml" title="CacheLib" href="/opensearch.xml"><title data-react-helmet="true">Configuring cachebench parameters | CacheLib</title><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:image" content="https://cachelib.org/img/CacheLib-Logo-small.png"><meta data-react-helmet="true" name="twitter:image" content="https://cachelib.org/img/CacheLib-Logo-small.png"><meta data-react-helmet="true" property="og:url" content="https://cachelib.org/docs/Cache_Library_User_Guides/Configuring_cachebench_parameters"><meta data-react-helmet="true" name="docsearch:language" content="en"><meta data-react-helmet="true" name="docsearch:version" content="current"><meta data-react-helmet="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-react-helmet="true" property="og:title" content="Configuring cachebench parameters | CacheLib"><meta data-react-helmet="true" name="description" content="Command line parameters"><meta data-react-helmet="true" property="og:description" content="Command line parameters"><link data-react-helmet="true" rel="shortcut icon" href="/img/favicon.ico"><link data-react-helmet="true" rel="canonical" href="https://cachelib.org/docs/Cache_Library_User_Guides/Configuring_cachebench_parameters"><link data-react-helmet="true" rel="alternate" href="https://cachelib.org/docs/Cache_Library_User_Guides/Configuring_cachebench_parameters" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://cachelib.org/docs/Cache_Library_User_Guides/Configuring_cachebench_parameters" hreflang="x-default"><link data-react-helmet="true" rel="preconnect" href="https://BH4D9OD16A-dsn.algolia.net" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.88c68b34.css">
<link rel="preload" href="/assets/js/runtime~main.d499e1a3.js" as="script">
<link rel="preload" href="/assets/js/main.70a77d5d.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script>
<div style="display: none; text-align: center; background-color: white; color: black;" id="internaldocs-banner"></div><div id="__docusaurus">
<div><a href="#" class="skipToContent_OuoZ">Skip to main content</a></div><div class="announcementBar_axC9" style="background-color:#20232a;color:#fff" role="banner"><div class="announcementBarContent_6uhP">Support Ukraine ðŸ‡ºðŸ‡¦ <a target="_blank" rel="noopener noreferrer" href="https://opensource.fb.com/support-ukraine"> Help Provide Humanitarian Aid to Ukraine</a>.</div></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><img src="/img/CacheLib-Logo-small.png" alt="My Facebook Project Logo" class="themedImage_TMUO themedImage--light_4Vu1 navbar__logo"><img src="/img/CacheLib-Logo-small.png" alt="My Facebook Project Logo" class="themedImage_TMUO themedImage--dark_uzRr navbar__logo"><b class="navbar__title">CacheLib</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/installation/installation">Build and Installation</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/">API and Usage</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/Cache_Library_User_Guides/Cachebench_Overview">Cachebench</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/Cache_Library_Architecture_Guide/overview_a_random_walk">Architecture Guide</a><a class="navbar__item navbar__link" href="/">â€Œ</a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/learnmore/">Learn More</a><a href="https://github.com/facebook/CacheLib" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><div class="react-toggle toggle_2i4l react-toggle--disabled"><div class="react-toggle-track" role="button" tabindex="-1"><div class="react-toggle-track-check"><span class="toggle_iYfV">ðŸŒœ</span></div><div class="react-toggle-track-x"><span class="toggle_iYfV">ðŸŒž</span></div><div class="react-toggle-thumb"></div></div><input type="checkbox" class="react-toggle-screenreader-only" aria-label="Switch between dark and light mode"></div><div class="searchBox_NKBi"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper docs-wrapper docs-doc-page"><div class="docPage_lDyR"><button class="clean-btn backToTopButton_i9tI" type="button"><svg viewBox="0 0 24 24" width="28"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z" fill="currentColor"></path></svg></button><aside class="docSidebarContainer_0YBq"><div class="sidebar_a3j0"><nav class="menu thin-scrollbar menu_cyFh menuWithAnnouncementBar_+O1J"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category menu__list-item"><a class="menu__link menu__link--sublist menu__link--active" href="#">Cachebench</a><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Cache_Library_User_Guides/Cachebench_Overview">Overview</a></li><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/Cache_Library_User_Guides/Configuring_cachebench_parameters">Configuring cachebench parameters</a></li><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Cache_Library_User_Guides/Developing_for_Cachebench">Contributing to Cachebench</a></li><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Cache_Library_User_Guides/Cachebench_FB_HW_eval">Evaluating SSD hardware for Facebook workloads</a></li></ul></li></ul></nav></div></aside><main class="docMainContainer_r8cw"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_XoVD"><div class="docItemContainer_6jsP"><article><header><h1 class="docTitle_ft6A">Configuring cachebench parameters</h1></header><div class="markdown"><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_y2LR" id="command-line-parameters"></a>Command line parameters<a class="hash-link" href="#command-line-parameters" title="Direct link to heading">#</a></h2><p>Cachebench takes command line parameters to control its behavior. The following are the semantics of the command line parameters:</p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_y2LR" id="json-test-configuration"></a>JSON test configuration<a class="hash-link" href="#json-test-configuration" title="Direct link to heading">#</a></h3><p><code>--json_test_config</code> is the most important command line parameter that is needed for  specifying the workoad and cache configuration for cachebench.  See the section below on JSON config for more details.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_y2LR" id="watching-progress"></a>Watching progress<a class="hash-link" href="#watching-progress" title="Direct link to heading">#</a></h3><p>While the benchmark runs, you can monitor the progress so far. The interval for progress update can be configured using the <code>--progress</code> and specifying a duration in seconds.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_y2LR" id="recording-periodic-stats"></a>Recording periodic stats<a class="hash-link" href="#recording-periodic-stats" title="Direct link to heading">#</a></h3><p>While the benchmark runs, you can have cachebench output a snapshot of its internal stats to a file periodically. To do this,   you have to pass a suitable file location to  <code>--progress_stats_file</code>. cachebench will appendd stats to this file every <code>--progress</code> interval.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_y2LR" id="stopping-after-a-certain-duration"></a>Stopping after a certain duration<a class="hash-link" href="#stopping-after-a-certain-duration" title="Direct link to heading">#</a></h3><p>If you would like cachebench to terminate after running for X hours, you can use <code>--timeout_seconds</code> to pass a suitable timeout.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_y2LR" id="sample-json-test-config"></a>Sample JSON test config<a class="hash-link" href="#sample-json-test-config" title="Direct link to heading">#</a></h3><p>Cachebench takes in a json config file that provides the workload and cache configuration. The following is a sample json config file:</p><div class="codeBlockContainer_J+bg"><div class="codeBlockContent_csEI"><pre tabindex="0" class="prism-code language-undefined codeBlock_rtdJ thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_1zSZ"><span class="token-line" style="color:#bfc7d5"><span class="token plain">{</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">   &quot;cache_config&quot; : {</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">     &quot;cacheSizeMB&quot; : 512,</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">     &quot;poolRebalanceIntervalSec&quot; : 1,</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">     &quot;moveOnSlabRelease&quot; : false,</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">     &quot;numPools&quot; : 2,</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">     &quot;poolSizes&quot; : [0.3, 0.7]</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">   },</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">   &quot;test_config&quot; : {</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">     &quot;numOps&quot; : 100000,</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">     &quot;numThreads&quot; : 32,</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">     &quot;numKeys&quot; : 1000000,</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">     &quot;distribution&quot; :  &quot;range&quot;,</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">     &quot;opDelayBatch&quot; : 1,</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">     &quot;opDelayNs&quot; : 200,</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">     &quot;keySizeRange&quot; : [1, 8, 64],</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">     &quot;keySizeRangeProbability&quot; : [0.3, 0.7],</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">     &quot;valSizeRange&quot; : [1, 32, 10240, 409200],</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">     &quot;valSizeRangeProbability&quot; : [0.1, 0.2, 0.7],</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">     &quot;getRatio&quot; : 0.15,</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">     &quot;setRatio&quot; : 0.8,</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">     &quot;delRatio&quot; : 0.05,</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">     &quot;keyPoolDistribution&quot;: [0.4, 0.6],</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">     &quot;opPoolDistribution&quot; : [0.5, 0.5]</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">   }</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block">
</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB clean-btn">Copy</button></div></div><p>This config file controls the parameters for the cache and the generated synthetic workload in two separate sections.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_y2LR" id="tuning-workload-parameters"></a>Tuning workload parameters<a class="hash-link" href="#tuning-workload-parameters" title="Direct link to heading">#</a></h2><p>You can tune the workload parameters by modifying the <code>test_config</code> portion of the json file. The workload generator operates over a key space and their associated sizes. It generates cachebench operations to be executed for those keys.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_y2LR" id="duration-of-replay"></a>Duration of replay<a class="hash-link" href="#duration-of-replay" title="Direct link to heading">#</a></h3><p>To run cachebench operation for longer, increase the <code>numOps</code> appropriately in the config file.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_y2LR" id="number-of-benchmark-threads"></a>Number of benchmark threads<a class="hash-link" href="#number-of-benchmark-threads" title="Direct link to heading">#</a></h3><p>You can adjust <code>numThreads</code> to run the benchmark with more threads. Running with more threads should increase throughput until you run out of cpu or hit other bottlenecks from resource contention. For in-memory workloads, it is not recommended to set this beyond the  hardware concurrency supported on your machine.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_y2LR" id="number-of-keys-in-cache"></a>Number of keys in cache<a class="hash-link" href="#number-of-keys-in-cache" title="Direct link to heading">#</a></h3><p>To adjust the working set size of the cache, you can increase or decrease the <code>numKeys</code> that the workload picks from.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_y2LR" id="operation-ratios"></a>Operation ratios<a class="hash-link" href="#operation-ratios" title="Direct link to heading">#</a></h3><p>Cachebench picks operation types by its specified popularity ratios. The following list the supported operation types:</p><ul><li><code>getRatio</code>
Generates a get request resulting in <code>find</code> API call.</li><li><code>setRatio</code>
Generates a set request by overriding any previous version of the key if it exists. This results in a call to the <code>allocate()</code> API, followed by a call to the <code>insertOrReplace()</code> API.</li><li><code>delRatio</code>
Generates a remove request to remove a key from the cache.</li><li><code>addChainedRatio</code>
Generates operations that allocate a chained allocation and adds it to the existing key. If the key is not present, it is created.</li><li><code>loneGetRatio</code>
Generates a get request for a key that is definitely not present in the cache to simulate one-hit-wonders or churn.</li></ul><p>In conjuction with these operations, <code>enableLookaside</code> emulates a behavior where missing keys are set in the cache. When this is used, <code>setRatio</code> is usually not configured.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_y2LR" id="workload-generator"></a>Workload generator<a class="hash-link" href="#workload-generator" title="Direct link to heading">#</a></h3><p>You can configure three types of workload generators through the <code>generator</code> parameter by specifying the corresponding identifier string.</p><ul><li><strong>workload</strong>
Generates keys and popularity ahead of time. This is the generator with the lowest run time overhead and hence is useful for measuring maximum throughput. The generator however consumes memory to keep keys and generated cache operations in memory and is not suitable when your memory footprint needs to be contained.</li><li><strong>online</strong>
Generates keys and popularity online. Has very low overhead in terms of memory, but consumes marginal CPU to generate synthetic workload.</li><li><strong>replay</strong>
Replays a trace file passed in. Tracefile should contain lines with csv separated key, size, and number of accesses.</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_y2LR" id="popularity-and-size-distribution"></a>Popularity and Size distribution<a class="hash-link" href="#popularity-and-size-distribution" title="Direct link to heading">#</a></h3><p>cachebench supports generating synthetic workloads using a few techniques. The technique is configured through the <em>distribution</em> argument. Based on the selected technique there can be additional parameters that can be configured. The supported techniques are</p><ul><li><p><strong>default</strong>
Generates popularity of keys through a discrete distribution specified in  <em>popularityBuckets</em> and <em>popularityWeights</em> parameter. Discrete sizes are generated through a discrete distribution specified through <code>valSizeRange</code> and <code>valSizeRangeProbability</code>. The value size configuration can be provided inline as an array or through a <code>valSizeDistFile</code> in json format.</p></li><li><p><strong>normal</strong>
Uses normal workload distribution for popularity of keys as opposed to discrete popularity buckets. For value sizes, it supports both discrete and continuous value size distribution. To use discrete value size distribution, the <code>valSizeRangeProbabilithy</code> should have same number of values as <code>valSizeRange</code> array. When <code>valSizeRangeProbabilithy</code> contains one less member than <code>valSizeRange</code>, we interpret the probability as corresponding to each interval in <code>valSizeRange</code> and use a piecewise_constant_distribution.</p></li></ul><p>In all above setups, cachebench overrides the <code>valSizeRange</code> and <code>vaSizeRangeProbability</code> from inline json array if <code>valSizeDistFile</code> is present.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_y2LR" id="throttling-the-benchmark"></a>Throttling the benchmark<a class="hash-link" href="#throttling-the-benchmark" title="Direct link to heading">#</a></h3><p>To measure the performance of HW at a certain throughput, cachebench can be artificially throttled by   specifying a non-zero <code>opDelayNs</code>, that is applied every <code>opDelayBatch</code> worth of operations per thread. To run un-throttled, set <code>opDelayNs</code> to zero.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_y2LR" id="consistency-checking"></a>Consistency checking<a class="hash-link" href="#consistency-checking" title="Direct link to heading">#</a></h3><p>You can enable runtime consistency checking of the APIs through cachebench. In this mode, cachebench validates the correctness semantics of API. This is useful when you make a cache to CacheLib and want to validate any data races resulting in incorrect API semantics.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_y2LR" id="populating-items"></a>Populating items<a class="hash-link" href="#populating-items" title="Direct link to heading">#</a></h3><p>You can enable <em>populateItem</em> to fill cache items with random bytes. When consistency mode is enabled, we populate the item automatically with unique values for validation.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_y2LR" id="tuning-dram-cache-parameters"></a>Tuning DRAM cache parameters<a class="hash-link" href="#tuning-dram-cache-parameters" title="Direct link to heading">#</a></h2><p>The <code>cache_config</code> section specifies knobs to control how the cache is configured. The following options are available to configure the DRAM cache parameters. DRAM cache parameters come into play when using hybrid cache as well as stand-alone DRAM cache mode.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_y2LR" id="dram-cache--size"></a>DRAM cache  size<a class="hash-link" href="#dram-cache--size" title="Direct link to heading">#</a></h3><p>You can set <code>cacheSizeMB</code> to specify the size of the DRAM cache.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_y2LR" id="allocator-type-and-its-eviction-parameters"></a>Allocator type and its eviction parameters<a class="hash-link" href="#allocator-type-and-its-eviction-parameters" title="Direct link to heading">#</a></h3><p>CacheLib supports LruAllocator and Lru2QAllocator to choose from. You can specify this by setting the <em>allocator</em> to &quot;LRU&quot; or &quot;LRU-2Q&quot;. Based on the type you choose you can configure the corresponding properties of DRAM eviction.</p><p>Common options for  LruAllocator and Lru2QAllocator:</p><ul><li><code>lruRefreshSec</code>
Seconds since last access that initiates a bump on access.</li><li><code>lruRefreshRatio</code>
Lru refresh time specified as a ratio of the eviction age.</li><li><code>lruUpdateOnRead</code>
Controls if read accesses lead to updating LRU position.</li><li><code>lruUpdateOnWrite</code>
Controls if write accesss lead to updating LRU position.</li><li><code>tryLockUpdate</code>
Skips updating the LRU position on contention.</li></ul><p>Options for LruAllocator:</p><ul><li><code>lruIpSpec</code>
Insertion point expressed as power of two.</li></ul><p>Options for Lru2QAllocator:</p><ul><li><code>lru2qHotPct</code>
Percentage of LRU dedicated for hot items</li><li><code>lru2qColdPct</code>
Percentage of LRU dedicated for cold items.</li></ul><p>For more details on the semantics of these parameters, see the documentation in <a href="/docs/Cache_Library_User_Guides/eviction_policy">Eviction Policy guide</a>.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_y2LR" id="pools"></a>Pools<a class="hash-link" href="#pools" title="Direct link to heading">#</a></h3><p>The DRAM cache can be split into multiple pools. To create the pools, you need to specify <code>numPools</code> to the required number of pools and set <code>poolSizes</code> array  to represent  the relative sizes of the pools.</p><p>When using pools, you can tune the workload to generate a different workload per pool. To split the keys and operations across pools, specify the following:</p><ul><li>Breakdown of keys through <code>keyPoolDistribution</code> array where each value represents the relative footprint of keys from <code>numKeys</code>.</li><li>Breakdown of operations per pool through <code>opPoolDistribution</code> where each value represents the relative footprint of <code>numOps</code> across pools.</li></ul><p>You can specify a seperate array of workload config that describes the key, size and popularity distribution per pool through <code>poolDistributionConfig</code>. If not specified, the global configuration is applied across all the pools.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_y2LR" id="allocation-sizes"></a>Allocation sizes<a class="hash-link" href="#allocation-sizes" title="Direct link to heading">#</a></h3><p>You can specify custom allocation sizes by passing in an <code>allocSizes</code> array. If <code>allocSizes</code> is not present, we use default allocation sizes with a factor of 1.5, starting from 64 bytes to 1MB. To control allocation sizes through alloc factor, you can specify <code>allocFactor</code> as a double and set <code>minAllocSize</code> and <code>maxAllocSize</code>.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_y2LR" id="access-config-parameters"></a>Access config parameters<a class="hash-link" href="#access-config-parameters" title="Direct link to heading">#</a></h3><p>CacheLib uses a hashtable to index keys. The configuration of the hashtable can have a big impact on throughput. <code>htBucketPower</code> controls the number of hashtable buckets and <code>htLockPower</code> configures the number of locks.  Usually, these should be configured in conjunction with the observed numItems in DRAM when the cache warms up.  See</p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_y2LR" id="pool-rebalancing"></a>Pool rebalancing<a class="hash-link" href="#pool-rebalancing" title="Direct link to heading">#</a></h3><p>To enable cachelib pool rebalancing techniques, you can set <code>poolRebalanceIntervalSec</code>. The default strategy is to randomly release a slab to test for correctness. You can configure this to your preference by setting <code>rebalanceStrategy</code> as &quot;tail-age&quot; or &quot;hits&quot;. You can also specify <code>rebalanceMinSlabs</code> and <code>rebalanceDiffRatio</code> to configure this further per documentation in <a href="/docs/Cache_Library_User_Guides/pool_rebalance_strategy">Pool rebalancing guide</a>.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_y2LR" id="hybrid-cache-parameters"></a>Hybrid cache parameters<a class="hash-link" href="#hybrid-cache-parameters" title="Direct link to heading">#</a></h2><p>Hybrid cache parameters are configured under the <code>cache_config</code> section. To enable hybrid cache for cachebench, you need to specify a non-zero value to the <code>nvmCacheSizeMB</code> parameter.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_y2LR" id="storage-filedevicedirectory-path-info"></a>Storage file/device/directory path info<a class="hash-link" href="#storage-filedevicedirectory-path-info" title="Direct link to heading">#</a></h3><p>You can configure hybrid cache in multiple modes.  By default, if you set only <code>nvmCacheSizeMB</code> and nothing else, cachebench will use an in-memory file device for simplicity. This is often used to test correctness quickly. To use an actual non-volatile medium, you can configure <code>nvmCachePaths</code>, which is taken as an array of strings.</p><p>If <code>nvmCachePaths</code> is set to a single element array that is a  directory, cachebench will create a suitable file inside the path and clean it up upon exit. Instead if <code>nvmCachePaths</code> is single element array referring to a file or a raw device, cachebench will use it as is and leave it as is upon exit.  If the file specified is a regular file and is not to the specified size, CacheLib will try to fallocate to the necessary size. If more than one path is specified, CacheLib will use software RAID-0 across them and treat each file to be of <code>nvmCacheSizeMB</code>.  By default, CacheLib uses direct io.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_y2LR" id="monitoring-write-amplification"></a>Monitoring write amplification<a class="hash-link" href="#monitoring-write-amplification" title="Direct link to heading">#</a></h3><p>CacheBench can monitor the write-amplification of supported underlying devices if you specify them through <code>writeAmpDeviceList</code> as an array of device paths. If the device is unsupported, an exception is logged, but the test proceeds. If this is empty, no monitoring is performed.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_y2LR" id="storage-engine-parameters"></a>Storage engine parameters<a class="hash-link" href="#storage-engine-parameters" title="Direct link to heading">#</a></h3><p>Set the following parameters to control the performance of the hybrid cache storage engine. See <a href="/docs/Cache_Library_User_Guides/HybridCache">Hybrid Cache</a> for more details.</p><ul><li><code>navyReaderThreads</code>  and <code>navyWriterThreads</code>
Control the reader and writer thread pools.</li><li><code>navyAdmissionWriteRateMB</code>
Throttle limit for logical write rate to maintain device endurance limit.</li><li><code>navyMaxConcurrentInserts</code>
Throttle limit for in-flight hybrid cache writes.</li><li><code>navyParcelMemoryMB</code>
Throttle limit for the memory footprint of in-flight writes.</li><li><code>navyDataChecksum</code>
Enables check-summing data in addition to the headers.</li><li><code>navyEncryption</code>
Enables transparent device level encryption.</li><li><code>navyReqOrderShardsPower</code>
Number of shards used for request ordering. The default is 21, corresponding to 2 million shards. The more shards, the less false positives and better concurrency. But this plateus beyond a certain number.</li><li><code>truncateItemToOriginalAllocSizeInNvm</code>
Truncates item to allocated size to optimize write performance.</li><li><code>deviceMaxWriteSize</code>
This controls the largest IO size we will write to the device. Any IO above this size will be split up into multiple IOs.</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_y2LR" id="small-item-engine-parameters"></a>Small item engine parameters<a class="hash-link" href="#small-item-engine-parameters" title="Direct link to heading">#</a></h3><p>Use the following options to tune the performance of the Small Item engine (BigHash): BigHash operates a FIFO cache on SSD and is optimized for caching small objects.</p><ul><li><code>navySmallItemMaxSize</code>
Object size threshold for small item engine.</li><li><code>navyBigHashSizePct</code>
When non-zero enables small item engine and its relative size.</li><li><code>navyBigHashBucketSize</code>
Bucket size for small item engine.</li><li><code>navyBloomFilterPerBucketSize</code>
Size in bytes for the bloom filter per bucket.</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_y2LR" id="large-item-engine-parameters"></a>Large item engine parameters<a class="hash-link" href="#large-item-engine-parameters" title="Direct link to heading">#</a></h3><p>Use the following options to tune the Large Item engine (BlockCache): Block cache is designed for caching objects that are around or larger than device block size. It can support variety of eviction policies from FIFO/LRU/SegmentedFIFO and can operate with stacked mode or size classes.</p><ul><li><code>navyBlockSize</code>
Underlying device block size for IO alignment.</li><li><code>navySizeClasses</code>
By default, cachebench uses a pre-determined array of sizes. Values are stored in slots rounded up to this size.  The default value is overridden by passing an array of sizes explicitly to control size classes. If an empty array is passed, Navy uses stacked mode.</li><li><code>navySegmentedFifoSegmentRatio</code>
By default Navy uses coarse grained LRU. To use FIFO, this parameter is set to an array with single value. To use segmented FIFO, this parameter is configured to control the number of segments by  specifying their ratios.</li><li><code>navyHitsReinsertionThreshold</code>
Control the threshold for reinserting items by their number of hits.</li><li><code>navyProbabilityReinsertionThreshold</code>
Control the probability based reinsertion of items.</li><li><code>navyNumInmemBuffers</code>
Number of memory buffers used to optimize write performance.</li><li><code>navyCleanRegions</code>
When un-buffered, the size of the clean regions pool.</li><li><code>navyRegionSizeMB</code>
This controls the region size to use for BlockCache. If not specified, 16MB will be used. See <a href="/docs/Cache_Library_User_Guides/Configure_HybridCache">Configure HybridCache</a> for more details.</li></ul></div></article><div class="margin-vert--xl"><div class="row"><div class="col"><a href="https://github.com/facebook/CacheLib/edit/main/website/docs/Cache_Library_User_Guides/Configuring_cachebench_parameters.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_mS5F" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div></div></div><div class="margin-vert--lg"><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/docs/Cache_Library_User_Guides/Cachebench_Overview"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Â« Overview</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/docs/Cache_Library_User_Guides/Developing_for_Cachebench"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Contributing to Cachebench Â»</div></a></div></nav></div></div></div><div class="col col--3"><div class="tableOfContents_vrFS thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#command-line-parameters" class="table-of-contents__link">Command line parameters</a><ul><li><a href="#json-test-configuration" class="table-of-contents__link">JSON test configuration</a></li><li><a href="#watching-progress" class="table-of-contents__link">Watching progress</a></li><li><a href="#recording-periodic-stats" class="table-of-contents__link">Recording periodic stats</a></li><li><a href="#stopping-after-a-certain-duration" class="table-of-contents__link">Stopping after a certain duration</a></li><li><a href="#sample-json-test-config" class="table-of-contents__link">Sample JSON test config</a></li></ul></li><li><a href="#tuning-workload-parameters" class="table-of-contents__link">Tuning workload parameters</a><ul><li><a href="#duration-of-replay" class="table-of-contents__link">Duration of replay</a></li><li><a href="#number-of-benchmark-threads" class="table-of-contents__link">Number of benchmark threads</a></li><li><a href="#number-of-keys-in-cache" class="table-of-contents__link">Number of keys in cache</a></li><li><a href="#operation-ratios" class="table-of-contents__link">Operation ratios</a></li><li><a href="#workload-generator" class="table-of-contents__link">Workload generator</a></li><li><a href="#popularity-and-size-distribution" class="table-of-contents__link">Popularity and Size distribution</a></li><li><a href="#throttling-the-benchmark" class="table-of-contents__link">Throttling the benchmark</a></li><li><a href="#consistency-checking" class="table-of-contents__link">Consistency checking</a></li><li><a href="#populating-items" class="table-of-contents__link">Populating items</a></li></ul></li><li><a href="#tuning-dram-cache-parameters" class="table-of-contents__link">Tuning DRAM cache parameters</a><ul><li><a href="#dram-cache--size" class="table-of-contents__link">DRAM cache  size</a></li><li><a href="#allocator-type-and-its-eviction-parameters" class="table-of-contents__link">Allocator type and its eviction parameters</a></li><li><a href="#pools" class="table-of-contents__link">Pools</a></li><li><a href="#allocation-sizes" class="table-of-contents__link">Allocation sizes</a></li><li><a href="#access-config-parameters" class="table-of-contents__link">Access config parameters</a></li><li><a href="#pool-rebalancing" class="table-of-contents__link">Pool rebalancing</a></li></ul></li><li><a href="#hybrid-cache-parameters" class="table-of-contents__link">Hybrid cache parameters</a><ul><li><a href="#storage-filedevicedirectory-path-info" class="table-of-contents__link">Storage file/device/directory path info</a></li><li><a href="#monitoring-write-amplification" class="table-of-contents__link">Monitoring write amplification</a></li><li><a href="#storage-engine-parameters" class="table-of-contents__link">Storage engine parameters</a></li><li><a href="#small-item-engine-parameters" class="table-of-contents__link">Small item engine parameters</a></li><li><a href="#large-item-engine-parameters" class="table-of-contents__link">Large item engine parameters</a></li></ul></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Reach Us</div><ul class="footer__items"><li class="footer__item"><a href="https://github.com/facebook/CacheLib" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items"><li class="footer__item"><a href="https://www.facebook.com/cachelib/" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Facebook Developer Page<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="https://twitter.com/MetaOpenSource" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div><div class="col footer__col"><div class="footer__title">Legal</div><ul class="footer__items"><li class="footer__item"><a href="https://opensource.facebook.com/legal/privacy/" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Privacy<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="https://opensource.facebook.com/legal/terms/" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Terms<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div></div><div class="footer__bottom text--center"><div class="margin-bottom--sm"><a href="https://opensource.facebook.com" target="_blank" rel="noopener noreferrer" class="footerLogoLink_SRtH"><img src="/img/oss_logo.png" alt="Facebook Open Source Logo" class="themedImage_TMUO themedImage--light_4Vu1 footer__logo"><img src="/img/oss_logo.png" alt="Facebook Open Source Logo" class="themedImage_TMUO themedImage--dark_uzRr footer__logo"></a></div><div class="footer__copyright">Copyright Â© 2022 Meta Platforms, Inc. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.d499e1a3.js"></script>
<script src="/assets/js/main.70a77d5d.js"></script>
</body>
</html>