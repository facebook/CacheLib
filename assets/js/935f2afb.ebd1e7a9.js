"use strict";(self.webpackChunkcachelib=self.webpackChunkcachelib||[]).push([[8581],{35610:e=>{e.exports=JSON.parse('{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"installationSidebar":[{"type":"category","label":"Installation and Usage","items":[{"type":"link","label":"Installation","href":"/docs/installation/","docId":"installation/installation"},{"type":"link","label":"Testing","href":"/docs/installation/testing","docId":"installation/testing"},{"type":"link","label":"CacheLib Website - Contributing to the docs","href":"/docs/installation/website","docId":"installation/website"},{"type":"link","label":"Github Repository Synchronization (after cleanup)","href":"/docs/installation/github-squash-sync","docId":"installation/github-squash-sync"}],"collapsed":true,"collapsible":true}],"userguideSidebar":[{"type":"link","label":"CacheLib user guide","href":"/docs/","docId":"cache_library_intro"},{"type":"category","label":"User Guide","collapsed":false,"items":[{"type":"category","label":"Overview","collapsed":true,"items":[{"type":"link","label":"About CacheLib","href":"/docs/Cache_Library_User_Guides/About_CacheLib","docId":"Cache_Library_User_Guides/About_CacheLib"},{"type":"link","label":"Terms","href":"/docs/Cache_Library_User_Guides/terms","docId":"Cache_Library_User_Guides/terms"}],"collapsible":true},{"type":"category","label":"Getting Started with Cache Library","collapsed":true,"items":[{"type":"link","label":"Set up a simple dram cache","href":"/docs/Cache_Library_User_Guides/Set_up_a_simple_cache","docId":"Cache_Library_User_Guides/Set_up_a_simple_cache"},{"type":"link","label":"Write data to cache","href":"/docs/Cache_Library_User_Guides/Write_data_to_cache","docId":"Cache_Library_User_Guides/Write_data_to_cache"},{"type":"link","label":"Read data from cache","href":"/docs/Cache_Library_User_Guides/Read_data_from_cache","docId":"Cache_Library_User_Guides/Read_data_from_cache"},{"type":"link","label":"Remove data from cache","href":"/docs/Cache_Library_User_Guides/Remove_data_from_cache","docId":"Cache_Library_User_Guides/Remove_data_from_cache"},{"type":"link","label":"Visit data in cache","href":"/docs/Cache_Library_User_Guides/Visit_data_in_cache","docId":"Cache_Library_User_Guides/Visit_data_in_cache"},{"type":"link","label":"FAQ","href":"/docs/Cache_Library_User_Guides/faq","docId":"Cache_Library_User_Guides/faq"}],"collapsible":true},{"type":"category","label":"Cache memory management","collapsed":true,"items":[{"type":"link","label":"Item and Handle","href":"/docs/Cache_Library_User_Guides/Item_and_Handle","docId":"Cache_Library_User_Guides/Item_and_Handle"},{"type":"link","label":"Eviction policy","href":"/docs/Cache_Library_User_Guides/eviction_policy","docId":"Cache_Library_User_Guides/eviction_policy"},{"type":"link","label":"Partition cache into pools","href":"/docs/Cache_Library_User_Guides/Partition_cache_into_pools","docId":"Cache_Library_User_Guides/Partition_cache_into_pools"},{"type":"link","label":"Configure lookup performance","href":"/docs/Cache_Library_User_Guides/Configure_HashTable","docId":"Cache_Library_User_Guides/Configure_HashTable"},{"type":"link","label":"Item Destructor","href":"/docs/Cache_Library_User_Guides/Item_Destructor","docId":"Cache_Library_User_Guides/Item_Destructor"},{"type":"link","label":"Remove callback","href":"/docs/Cache_Library_User_Guides/Remove_callback","docId":"Cache_Library_User_Guides/Remove_callback"},{"type":"link","label":"Cache persistence","href":"/docs/Cache_Library_User_Guides/Cache_persistence","docId":"Cache_Library_User_Guides/Cache_persistence"},{"type":"link","label":"Cross Host Cache Persistence","href":"/docs/Cache_Library_User_Guides/Cross_Host_Cache_Persistence","docId":"Cache_Library_User_Guides/Cross_Host_Cache_Persistence"},{"type":"link","label":"TTL Reaper","href":"/docs/Cache_Library_User_Guides/ttl_reaper","docId":"Cache_Library_User_Guides/ttl_reaper"},{"type":"link","label":"Oom protection","href":"/docs/Cache_Library_User_Guides/oom_protection","docId":"Cache_Library_User_Guides/oom_protection"},{"type":"link","label":"Pool rebalance strategy","href":"/docs/Cache_Library_User_Guides/pool_rebalance_strategy","docId":"Cache_Library_User_Guides/pool_rebalance_strategy"},{"type":"link","label":"Automatic pool resizing","href":"/docs/Cache_Library_User_Guides/automatic_pool_resizing","docId":"Cache_Library_User_Guides/automatic_pool_resizing"}],"collapsible":true},{"type":"category","label":"Hybrid Cache","collapsed":true,"items":[{"type":"link","label":"HybridCache","href":"/docs/Cache_Library_User_Guides/HybridCache","docId":"Cache_Library_User_Guides/HybridCache"},{"type":"link","label":"Configure HybridCache","href":"/docs/Cache_Library_User_Guides/Configure_HybridCache","docId":"Cache_Library_User_Guides/Configure_HybridCache"}],"collapsible":true},{"type":"category","label":"Advanced Features","collapsed":true,"items":[{"type":"link","label":"Chained items","href":"/docs/Cache_Library_User_Guides/chained_items","docId":"Cache_Library_User_Guides/chained_items"},{"type":"link","label":"Compact cache","href":"/docs/Cache_Library_User_Guides/compact_cache","docId":"Cache_Library_User_Guides/compact_cache"},{"type":"link","label":"Structured cache","href":"/docs/Cache_Library_User_Guides/Structured_Cache","docId":"Cache_Library_User_Guides/Structured_Cache"},{"type":"link","label":"FDP enabled cache","href":"/docs/Cache_Library_User_Guides/FDP_enabled_Cache","docId":"Cache_Library_User_Guides/FDP_enabled_Cache"}],"collapsible":true},{"type":"category","label":"Reference","collapsed":true,"items":[{"type":"link","label":"Tuning DRAM cache efficiency","href":"/docs/Cache_Library_User_Guides/Tuning_DRAM_cache_efficiency","docId":"Cache_Library_User_Guides/Tuning_DRAM_cache_efficiency"},{"type":"link","label":"CacheLib configs","href":"/docs/Cache_Library_User_Guides/CacheLib_configs","docId":"Cache_Library_User_Guides/CacheLib_configs"}],"collapsible":true}],"collapsible":true}],"cachebenchSideBar":[{"type":"category","label":"Cachebench","collapsed":true,"items":[{"type":"link","label":"Overview","href":"/docs/Cache_Library_User_Guides/Cachebench_Overview","docId":"Cache_Library_User_Guides/Cachebench_Overview"},{"type":"link","label":"Configuring cachebench parameters","href":"/docs/Cache_Library_User_Guides/Configuring_cachebench_parameters","docId":"Cache_Library_User_Guides/Configuring_cachebench_parameters"},{"type":"link","label":"Contributing to Cachebench","href":"/docs/Cache_Library_User_Guides/Developing_for_Cachebench","docId":"Cache_Library_User_Guides/Developing_for_Cachebench"},{"type":"link","label":"Evaluating SSD hardware for Facebook workloads","href":"/docs/Cache_Library_User_Guides/Cachebench_FB_HW_eval","docId":"Cache_Library_User_Guides/Cachebench_FB_HW_eval"}],"collapsible":true}],"archguideSideBar":[{"type":"category","label":"Architecture Guide","collapsed":false,"items":[{"type":"category","label":"Overview","collapsed":true,"items":[{"type":"link","label":"Overview: A random walk down the Cache Library","href":"/docs/Cache_Library_Architecture_Guide/overview_a_random_walk","docId":"Cache_Library_Architecture_Guide/overview_a_random_walk"},{"type":"link","label":"Cachelib Common Components","href":"/docs/Cache_Library_Architecture_Guide/common_components","docId":"Cache_Library_Architecture_Guide/common_components"}],"collapsible":true},{"type":"category","label":"RAM Cache","collapsed":true,"items":[{"type":"link","label":"RAM Cache Design","href":"/docs/Cache_Library_Architecture_Guide/ram_cache_design","docId":"Cache_Library_Architecture_Guide/ram_cache_design"},{"type":"link","label":"RAM cache indexing and eviction","href":"/docs/Cache_Library_Architecture_Guide/ram_cache_indexing_and_eviction","docId":"Cache_Library_Architecture_Guide/ram_cache_indexing_and_eviction"},{"type":"link","label":"Slab Rebalancing - How Does It Work?","href":"/docs/Cache_Library_Architecture_Guide/slab_rebalancing","docId":"Cache_Library_Architecture_Guide/slab_rebalancing"},{"type":"link","label":"Synchronization between Eviction & Slab-movement","href":"/docs/Cache_Library_Architecture_Guide/synchronization_in_eviction_and_slab_rebalancing","docId":"Cache_Library_Architecture_Guide/synchronization_in_eviction_and_slab_rebalancing"},{"type":"link","label":"Compact Cache Design","href":"/docs/Cache_Library_Architecture_Guide/compact_cache_design","docId":"Cache_Library_Architecture_Guide/compact_cache_design"}],"collapsible":true},{"type":"category","label":"Hybrid Cache","collapsed":true,"items":[{"type":"link","label":"Hybrid Cache","href":"/docs/Cache_Library_Architecture_Guide/hybrid_cache","docId":"Cache_Library_Architecture_Guide/hybrid_cache"},{"type":"link","label":"Navy Overview","href":"/docs/Cache_Library_Architecture_Guide/navy_overview","docId":"Cache_Library_Architecture_Guide/navy_overview"},{"type":"link","label":"Small Object Cache","href":"/docs/Cache_Library_Architecture_Guide/small_object_cache","docId":"Cache_Library_Architecture_Guide/small_object_cache"},{"type":"link","label":"Large Object Cache","href":"/docs/Cache_Library_Architecture_Guide/large_object_cache","docId":"Cache_Library_Architecture_Guide/large_object_cache"}],"collapsible":true}],"collapsible":true}]},"docs":{"Cache_Library_Architecture_Guide/common_components":{"id":"Cache_Library_Architecture_Guide/common_components","title":"Cachelib Common Components","description":"cachelib/common has a number of helper classes that we use throughout the codebase. You\'re free to use them in your own projects as well. This page will give an overview to each of the components.","sidebar":"archguideSideBar"},"Cache_Library_Architecture_Guide/compact_cache_design":{"id":"Cache_Library_Architecture_Guide/compact_cache_design","title":"Compact Cache Design","description":"What is Compact Cache?","sidebar":"archguideSideBar"},"Cache_Library_Architecture_Guide/hybrid_cache":{"id":"Cache_Library_Architecture_Guide/hybrid_cache","title":"Hybrid Cache","description":"CacheLib supports use of multiple HW mediums through hybrid cache feature. To make this transparent to the user, the CacheAllocator API is extended to support caching items in both DRAM and NVM. Barring few features, users should not be aware of whether the Item is cached in DRAM or NVM.","sidebar":"archguideSideBar"},"Cache_Library_Architecture_Guide/large_object_cache":{"id":"Cache_Library_Architecture_Guide/large_object_cache","title":"Large Object Cache","description":"The Large Object Cache (LOC, also known as BlockCache) caches objects that are","sidebar":"archguideSideBar"},"Cache_Library_Architecture_Guide/navy_overview":{"id":"Cache_Library_Architecture_Guide/navy_overview","title":"Navy Overview","description":"Navy is the SSD optimized cache engine leveraged for Hybrid Cache. Navy is plugged into cachelib via the nvmcache interface and turned on by NavyConfig.","sidebar":"archguideSideBar"},"Cache_Library_Architecture_Guide/overview_a_random_walk":{"id":"Cache_Library_Architecture_Guide/overview_a_random_walk","title":"Overview: A random walk down the Cache Library","description":"This guide is intended for people without background knowledge in CacheLib who","sidebar":"archguideSideBar"},"Cache_Library_Architecture_Guide/ram_cache_design":{"id":"Cache_Library_Architecture_Guide/ram_cache_design","title":"RAM Cache Design","description":"This is a high level document that explains the design of different components within RAM cache and how they fit together and work. This is a good place to learn about the language for terms in the code as well.","sidebar":"archguideSideBar"},"Cache_Library_Architecture_Guide/ram_cache_indexing_and_eviction":{"id":"Cache_Library_Architecture_Guide/ram_cache_indexing_and_eviction","title":"RAM cache indexing and eviction","description":"This article takes a deep look at CacheLib\'s RAM cache\'s AccessContainer and","sidebar":"archguideSideBar"},"Cache_Library_Architecture_Guide/slab_rebalancing":{"id":"Cache_Library_Architecture_Guide/slab_rebalancing","title":"Slab Rebalancing - How Does It Work?","description":"Goal","sidebar":"archguideSideBar"},"Cache_Library_Architecture_Guide/small_object_cache":{"id":"Cache_Library_Architecture_Guide/small_object_cache","title":"Small Object Cache","description":"The Small Object Cache (SOC)   caches objects that are 100s of bytes in size using 100s of GB of SSD. SOC is implemented as a set associative cache to reduce the DRAM overhead for indexing.  SOC is initialized with large range of blocks specified through a start offset and size.","sidebar":"archguideSideBar"},"Cache_Library_Architecture_Guide/synchronization_in_eviction_and_slab_rebalancing":{"id":"Cache_Library_Architecture_Guide/synchronization_in_eviction_and_slab_rebalancing","title":"Synchronization between Eviction & Slab-movement","description":"Overview","sidebar":"archguideSideBar"},"cache_library_intro":{"id":"cache_library_intro","title":"CacheLib user guide","description":"Cache library (CacheLib) is a C++ library for accessing and managing cache data. It is a","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/About_CacheLib":{"id":"Cache_Library_User_Guides/About_CacheLib","title":"About CacheLib","description":"CacheLib is a C++ library for accessing and managing cache data. It is a thread-safe API that enables developers to build and customize scalable, concurrent caches. It is targeted at applications that dedicate gigabytes of memory to cache information.","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/automatic_pool_resizing":{"id":"Cache_Library_User_Guides/automatic_pool_resizing","title":"Automatic pool resizing","description":"This feature is incomplete and untested in prod. If you\'re interested, reach out to us and we can work out a plan to complete it.","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/Cache_persistence":{"id":"Cache_Library_User_Guides/Cache_persistence","title":"Cache persistence","description":"Cachelib supports persisting the cache across process restarts. This is useful when you want to restart your binary that contains a  cache and not lose the cache upon restart.  Cache persistence only works when you restart your process in the same machine. This does not provide persistence across machines.","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/Cachebench_FB_HW_eval":{"id":"Cache_Library_User_Guides/Cachebench_FB_HW_eval","title":"Evaluating SSD hardware for Facebook workloads","description":"CacheBench is a cache benchmark tool used to stress the storage and","sidebar":"cachebenchSideBar"},"Cache_Library_User_Guides/Cachebench_Overview":{"id":"Cache_Library_User_Guides/Cachebench_Overview","title":"Overview","description":"CacheBench is a benchmark and stress testing  tool to evaluate cache","sidebar":"cachebenchSideBar"},"Cache_Library_User_Guides/CacheLib_configs":{"id":"Cache_Library_User_Guides/CacheLib_configs","title":"CacheLib configs","description":"This document covers the configs that CacheLib cache consumes. In general there are two types of configs: the static ones that are consumed only when CacheAllocator is constructed, the dynamic ones that can be updated without restarting CacheAllocator.","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/chained_items":{"id":"Cache_Library_User_Guides/chained_items","title":"Chained items","description":"The allocate() method allocates memory for data whose size is less than the maximum allocation size (default: 4MB). To cache data whose size exceeds maximum allocation size, use chained allocations.","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/compact_cache":{"id":"Cache_Library_User_Guides/compact_cache","title":"Compact cache","description":"This feature is in maintenance mode. All future development plans are dropped. We understand there is value in optimizing for very small payloads, but we think the correct direction is to reduce item overhead in the regular cache instead of adding small, separate caches that offer low space overhead. Please reach out to us directly if you have a strong need for a RAM cache optimized for very small items.","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/Configure_HashTable":{"id":"Cache_Library_User_Guides/Configure_HashTable","title":"Configure lookup performance","description":"When you use a cache instance, it comes with a hash table that the find() method uses to look up an item in cache by its key. The current implementation uses a chained, open addressable hash table for keeping the lookup performance as small as possible. There are a few knobs to tune that will impact the lookup and insert cost of the cache. For this reason, the default parameters for this are left as the most-unoptimized state. To tune the HashTable, you need configure two important parameters in the AccessConfig type in your cache.","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/Configure_HybridCache":{"id":"Cache_Library_User_Guides/Configure_HybridCache","title":"Configure HybridCache","description":"Enabling hybrid cache","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/Configuring_cachebench_parameters":{"id":"Cache_Library_User_Guides/Configuring_cachebench_parameters","title":"Configuring cachebench parameters","description":"Command line parameters","sidebar":"cachebenchSideBar"},"Cache_Library_User_Guides/Cross_Host_Cache_Persistence":{"id":"Cache_Library_User_Guides/Cross_Host_Cache_Persistence","title":"Cross Host Cache Persistence","description":"Cachelib supports persisting the cache into a remote storage and restoring in a","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/Developing_for_Cachebench":{"id":"Cache_Library_User_Guides/Developing_for_Cachebench","title":"Contributing to Cachebench","description":"CacheBench provides features to model cache workloads, represent cache workloads, to run cache benchmarks and more. This guide will explain how CacheBench is structured and how to add new configs or build features for it.","sidebar":"cachebenchSideBar"},"Cache_Library_User_Guides/doc5":{"id":"Cache_Library_User_Guides/doc5","title":"CacheLib User Guide","description":"Will be published soon..."},"Cache_Library_User_Guides/eviction_policy":{"id":"Cache_Library_User_Guides/eviction_policy","title":"Eviction policy","description":"Cachelib offers different eviction policies, suitable for different use cases. To select a specific eviction policy, choose the appropriate allocator type.","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/faq":{"id":"Cache_Library_User_Guides/faq","title":"FAQ","description":"My cache instance is broken. Help!","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/FDP_enabled_Cache":{"id":"Cache_Library_User_Guides/FDP_enabled_Cache","title":"FDP enabled cache","description":"NVMe\xae Flexible Data Placement (NVMe\xae FDP)","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/HybridCache":{"id":"Cache_Library_User_Guides/HybridCache","title":"HybridCache","description":"HybridCache feature enables CacheAllocator to extend the DRAM cache to NVM. With HybridCache, cachelib can seamlessly move Items stored in cache across DRAM and NVM as they are accessed. Using HybridCache, you can shrink your DRAM footprint of the cache and replace it with NVM like Flash. This can also enable you to achieve large cache capacities for the same or relatively lower power and dollar cost.","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/Item_and_Handle":{"id":"Cache_Library_User_Guides/Item_and_Handle","title":"Item and Handle","description":"An item is the fundamental memory allocation backing an object in cache. Throughout this guide, we sometimes use item and allocation interchangeably. We use allocation when we discuss memory allocation or footprint. And we use item when we want to emphasize cached objects. An item is associated with a key and a byte array allocated by the allocate() method. We use the key to look up the item.","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/Item_Destructor":{"id":"Cache_Library_User_Guides/Item_Destructor","title":"Item Destructor","description":"Introduction","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/oom_protection":{"id":"Cache_Library_User_Guides/oom_protection","title":"Oom protection","description":"Cachelib can dynamically grow or shrink the total cache footprint from its configured size based on the memory pressure in your system. We call this feature MemoryMonitor. When it is enabled, cachelib watches for the memory pressure through system metrics and releases cache memory back to the system. When the memory pressure eases, cachelib can reclaim back the memory and grow to its configured size. MemoryMonitor enables you to size your cache without having to worry about your system\'s running out of memory when regular heap memory grows or system free memory drops. It also enables you to be less relaxed about coming up with an optimal cache size or relaxing the head room you need to maintain in anticipation of sudden memory growth.","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/Partition_cache_into_pools":{"id":"Cache_Library_User_Guides/Partition_cache_into_pools","title":"Partition cache into pools","description":"One easy way to manage your cache\'s memory is to partition it into pools. This is useful when your application has knowledge of different objects and you want to cache them into different pools or you want to set cache memory limits based on application specific context. For example, if you are caching photos on a 20 GB cache, you can separate celebrity photos from cat photos by storing them in two different pools and restrict the size of each pool.","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/pool_rebalance_strategy":{"id":"Cache_Library_User_Guides/pool_rebalance_strategy","title":"Pool rebalance strategy","description":"When do you need pool rebalancing?","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/Read_data_from_cache":{"id":"Cache_Library_User_Guides/Read_data_from_cache","title":"Read data from cache","description":"An item written to cache by cachelib is associated with a key. To read the item from cache, call the find() method (defined in allocator/CacheAllocator.h) with the key to look up the item:","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/Remove_callback":{"id":"Cache_Library_User_Guides/Remove_callback","title":"Remove callback","description":"Use Item Destructor whenever is possible, contact us if it","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/Remove_data_from_cache":{"id":"Cache_Library_User_Guides/Remove_data_from_cache","title":"Remove data from cache","description":"To remove data from cache, call these methods declared in allocator/CacheAllocator.h:","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/Set_up_a_simple_cache":{"id":"Cache_Library_User_Guides/Set_up_a_simple_cache","title":"Set up a simple dram cache","description":"Before calling cachelib to cache your data, set up a simple dram cache first.","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/Structured_Cache":{"id":"Cache_Library_User_Guides/Structured_Cache","title":"Structured cache","description":"Cachelib enables you to build structured data on top of a cache instead of treating it as just a blob-cache. Data structures let you focus on the actual logic instead of being worried about where a memory allocation comes from. Of course, we\'re still bound by physical limits such as the 4 MB ceiling for any single piece of allocations, but in practice we rarely need to make use of that big an allocation. We provide a generic memory allocator that can take in one or more buffers of memory (one buffer correspond to an item type in cache). Cachelib data types are built by making use of this memory allocator.","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/terms":{"id":"Cache_Library_User_Guides/terms","title":"Terms","description":"Item","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/ttl_reaper":{"id":"Cache_Library_User_Guides/ttl_reaper","title":"TTL Reaper","description":"Cachelib allocators support time to live (TTL) on an item natively at the granularity of seconds. When you set a TTL on an item, the item is automatically reaped if it is still present in the cache after its expiry.  The find() method returns an empty handle (nullptr) for an item that has expired.","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/Tuning_DRAM_cache_efficiency":{"id":"Cache_Library_User_Guides/Tuning_DRAM_cache_efficiency","title":"Tuning DRAM cache efficiency","description":"Reduce fragmentation","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/Visit_data_in_cache":{"id":"Cache_Library_User_Guides/Visit_data_in_cache","title":"Visit data in cache","description":"Cachelib provides a concurrent iterator to visit unchained data (items) in a cache while other threads are inserting data to or removing data from the cache. At any time, an item visited by the iterator is guaranteed to be valid even if it is concurrently removed by another thread.","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/Write_data_to_cache":{"id":"Cache_Library_User_Guides/Write_data_to_cache","title":"Write data to cache","description":"After setting up your cache, you can start writing data to it.","sidebar":"userguideSidebar"},"facebook/Cache_Library_onboarding_questionnaire":{"id":"facebook/Cache_Library_onboarding_questionnaire","title":"Onboarding Questionnaire","description":"To help us understand your use case and provide you effective advice, please copy this gdoc template and share it in a post to our user group."},"facebook/Cache_Monitoring/Add_monitoring_for_cache":{"id":"facebook/Cache_Monitoring/Add_monitoring_for_cache","title":"Add monitoring for cache","description":"Now that we have a working cache. We need to add monitoring to it. Without ODS and Scuba monitoring, you would be flying blind regarding the performance and health of your cache. CacheLib offers comprehensive monitoring support, and we\'ll walk you through how to set it up below."},"facebook/Cache_Monitoring/Cache_Admin_Overview":{"id":"facebook/Cache_Monitoring/Cache_Admin_Overview","title":"Cache Admin Overview","description":"CacheAdmin is a component for monitoring the cache health for CacheLib cache. Its purpose is to fetch cache stats from Cache, and then upload them to ODS or Scuba as appropriate. The code is located in fbcode/cachelib/facebook/admin/. CacheAdmin contains the following components. As you can see, we separate them into roughly three groups per their update interval."},"facebook/Cache_Monitoring/monitoring":{"id":"facebook/Cache_Monitoring/monitoring","title":"Monitoring cache health","description":"Cachelib offers both ODS and Scuba monitoring for your cache health. To enable monitoring, see Add monitoring for cache. In Scuba and ODS, you can find such information as hit rate, rate of allocations, eviction age, fragmentation, etc. This comprehensive set of metrics helps you to know how well your cache is performing or to debug issues related to your cachelib usage."},"facebook/Cache_Monitoring/understanding_nvm_latency":{"id":"facebook/Cache_Monitoring/understanding_nvm_latency","title":"Understanding Nvm Latency","description":"In this doc, we describe how to interpret the latency numbers in NVM operations."},"facebook/Cache_Persistence/Cross_Host_Persistence_APIs_Internal":{"id":"facebook/Cache_Persistence/Cross_Host_Persistence_APIs_Internal","title":"Cross Host Persistence APIs (internal)","description":"Introduction"},"facebook/Cache_Persistence/TW_shm_persistence_setup":{"id":"facebook/Cache_Persistence/TW_shm_persistence_setup","title":"TW shared memory persistence setup","description":"POSIX setup"},"facebook/Cachelib_Developers/Cachelib_onboarding_guide":{"id":"facebook/Cachelib_Developers/Cachelib_onboarding_guide","title":"CacheLib Onboarding Guide","description":"Team Culture"},"facebook/Cachelib_Developers/How_To_Debug_A_Core":{"id":"facebook/Cachelib_Developers/How_To_Debug_A_Core","title":"How To Debug A Core","description":"[WORK IN PROGRESS]"},"facebook/internal-test":{"id":"facebook/internal-test","title":"An Internal Document Section Test","description":"This is an internal document section."},"facebook/Object_Cache/Object_Cache_Architecture_Guide":{"id":"facebook/Object_Cache/Object_Cache_Architecture_Guide","title":"Object-Cache Design","description":"Introduction"},"facebook/Object_Cache/Object_Cache_Decision_Guide":{"id":"facebook/Object_Cache/Object_Cache_Decision_Guide","title":"CacheLib Object Cache Decision Guide","description":"Goal"},"facebook/Object_Cache/Object_Cache_User_Guide":{"id":"facebook/Object_Cache/Object_Cache_User_Guide","title":"CacheLib Object Cache User Guide","description":"Object-Cache enables users to cache C++ objects natively in CacheLib."},"facebook/website-internal":{"id":"facebook/website-internal","title":"Website Updates - FB Internals","description":"Internal Static Docs"},"facebook/Working_Set_Analysis/Enabling_WSA":{"id":"facebook/Working_Set_Analysis/Enabling_WSA","title":"Enabling WSA","description":"Enabling Working Set Analysis logging in Cache Library"},"facebook/Working_Set_Analysis/WSA_analysis_and_optimizations":{"id":"facebook/Working_Set_Analysis/WSA_analysis_and_optimizations","title":"Analysis and Optimizations","description":"We are currently working on the following cache analyses. By the end of 2021H1 we hope to update this page with a link to an /intern/ tool where WSA users can view the results of these analyses. Until then, please reach out to the WSA team for pointers to Hive tables containing the results."},"facebook/Working_Set_Analysis/WSA_helpful_definitions":{"id":"facebook/Working_Set_Analysis/WSA_helpful_definitions","title":"Helpful Definitions","description":"Context"},"facebook/Working_Set_Analysis/WSA_logging_library":{"id":"facebook/Working_Set_Analysis/WSA_logging_library","title":"A practical guide to Working Set Analysis Logging Library","description":"This page describes about how you can add logging supported by Working Set Analysis Logging Library into your c++ code base."},"facebook/Working_Set_Analysis/WSA_overview":{"id":"facebook/Working_Set_Analysis/WSA_overview","title":"Working Set Analysis Overview","description":"POCs"},"installation/github-squash-sync":{"id":"installation/github-squash-sync","title":"Github Repository Synchronization (after cleanup)","description":"In preparation of making CacheLib public, the CacheLib github repository","sidebar":"installationSidebar"},"installation/installation":{"id":"installation/installation","title":"Installation","description":"Dependencies","sidebar":"installationSidebar"},"installation/testing":{"id":"installation/testing","title":"Testing","description":"Cachelib includes many unit tests for various components","sidebar":"installationSidebar"},"installation/website":{"id":"installation/website","title":"CacheLib Website - Contributing to the docs","description":"CacheLib Website Overview","sidebar":"installationSidebar"}}}')}}]);