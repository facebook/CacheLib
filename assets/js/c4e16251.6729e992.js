"use strict";(self.webpackChunkcachelib=self.webpackChunkcachelib||[]).push([[3018],{3905:function(e,n,t){t.r(n),t.d(n,{MDXContext:function(){return l},MDXProvider:function(){return p},mdx:function(){return f},useMDXComponents:function(){return h},withMDXComponents:function(){return d}});var a=t(67294);function r(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function i(){return i=Object.assign||function(e){for(var n=1;n<arguments.length;n++){var t=arguments[n];for(var a in t)Object.prototype.hasOwnProperty.call(t,a)&&(e[a]=t[a])}return e},i.apply(this,arguments)}function o(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function c(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?o(Object(t),!0).forEach((function(n){r(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function s(e,n){if(null==e)return{};var t,a,r=function(e,n){if(null==e)return{};var t,a,r={},i=Object.keys(e);for(a=0;a<i.length;a++)t=i[a],n.indexOf(t)>=0||(r[t]=e[t]);return r}(e,n);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)t=i[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var l=a.createContext({}),d=function(e){return function(n){var t=h(n.components);return a.createElement(e,i({},n,{components:t}))}},h=function(e){var n=a.useContext(l),t=n;return e&&(t="function"==typeof e?e(n):c(c({},n),e)),t},p=function(e){var n=h(e.components);return a.createElement(l.Provider,{value:n},e.children)},u={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},m=a.forwardRef((function(e,n){var t=e.components,r=e.mdxType,i=e.originalType,o=e.parentName,l=s(e,["components","mdxType","originalType","parentName"]),d=h(t),p=r,m=d["".concat(o,".").concat(p)]||d[p]||u[p]||i;return t?a.createElement(m,c(c({ref:n},l),{},{components:t})):a.createElement(m,c({ref:n},l))}));function f(e,n){var t=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var i=t.length,o=new Array(i);o[0]=m;var c={};for(var s in n)hasOwnProperty.call(n,s)&&(c[s]=n[s]);c.originalType=e,c.mdxType="string"==typeof e?e:r,o[1]=c;for(var l=2;l<i;l++)o[l]=t[l];return a.createElement.apply(null,o)}return a.createElement.apply(null,t)}m.displayName="MDXCreateElement"},11693:function(e,n,t){t.r(n),t.d(n,{assets:function(){return d},contentTitle:function(){return s},default:function(){return u},frontMatter:function(){return c},metadata:function(){return l},toc:function(){return h}});var a=t(83117),r=t(80102),i=(t(67294),t(3905)),o=["components"],c={id:"Developing_for_Cachebench",title:"Contributing to Cachebench"},s=void 0,l={unversionedId:"Cache_Library_User_Guides/Developing_for_Cachebench",id:"Cache_Library_User_Guides/Developing_for_Cachebench",title:"Contributing to Cachebench",description:"CacheBench provides features to model cache workloads, represent cache workloads, to run cache benchmarks and more. This guide will explain how CacheBench is structured and how to add new configs or build features for it.",source:"@site/docs/Cache_Library_User_Guides/Developing_for_Cachebench.md",sourceDirName:"Cache_Library_User_Guides",slug:"/Cache_Library_User_Guides/Developing_for_Cachebench",permalink:"/docs/Cache_Library_User_Guides/Developing_for_Cachebench",draft:!1,editUrl:"https://github.com/facebook/CacheLib/edit/main/website/docs/Cache_Library_User_Guides/Developing_for_Cachebench.md",tags:[],version:"current",frontMatter:{id:"Developing_for_Cachebench",title:"Contributing to Cachebench"},sidebar:"cachebenchSideBar",previous:{title:"Configuring cachebench parameters",permalink:"/docs/Cache_Library_User_Guides/Configuring_cachebench_parameters"},next:{title:"Evaluating SSD hardware for Facebook workloads",permalink:"/docs/Cache_Library_User_Guides/Cachebench_FB_HW_eval"}},d={},h=[{value:"Anatomy of CacheBench",id:"anatomy-of-cachebench",level:2},{value:"Write a new config",id:"write-a-new-config",level:2},{value:"Simple config with key-value sizes and popularity distribution",id:"simple-config-with-key-value-sizes-and-popularity-distribution",level:3},{value:"Real world config example",id:"real-world-config-example",level:3},{value:"Replay production cache traces",id:"replay-production-cache-traces",level:3},{value:"Writing a new workload generator",id:"writing-a-new-workload-generator",level:2}],p={toc:h};function u(e){var n=e.components,c=(0,r.Z)(e,o);return(0,i.mdx)("wrapper",(0,a.Z)({},p,c,{components:n,mdxType:"MDXLayout"}),(0,i.mdx)("p",null,"CacheBench provides features to model cache workloads, represent cache workloads, to run cache benchmarks and more. This guide will explain how CacheBench is structured and how to add new configs or build features for it."),(0,i.mdx)("h2",{id:"anatomy-of-cachebench"},"Anatomy of CacheBench"),(0,i.mdx)("p",null,"CacheBench consists of several components, each organized under a\nsub-directory inside ",(0,i.mdx)("inlineCode",{parentName:"p"},"CacheLib/cachebench"),".  ",(0,i.mdx)("img",{src:t(45964).Z,width:"1148",height:"391"})),(0,i.mdx)("p",null,"When CacheBench starts up, it reads the config file passed through\n",(0,i.mdx)("inlineCode",{parentName:"p"},"--json_test_config")," through the utilities present in ",(0,i.mdx)("inlineCode",{parentName:"p"},"cachebench/util"),". Once\nthe stress test config is parsed, it is passed to initialize a workload\ngenerator (see under ",(0,i.mdx)("inlineCode",{parentName:"p"},"cachebench/workload"),") and a test ",(0,i.mdx)("inlineCode",{parentName:"p"},"Runner"),"(see under\n",(0,i.mdx)("inlineCode",{parentName:"p"},"cachebench/runner"),"). The ",(0,i.mdx)("inlineCode",{parentName:"p"},"Runner")," operates the stress test by invoking the\nappropriate ",(0,i.mdx)("inlineCode",{parentName:"p"},"Stressor")," implementation and passes the workload generator to the\nstressor for generating the traffic if appropriate. ",(0,i.mdx)("inlineCode",{parentName:"p"},"CacheStressor")," is the\ncommonly used implementation to continue running the workload against an\ninstance of CacheLib cache (see under ",(0,i.mdx)("inlineCode",{parentName:"p"},"cachebench/cache"),"). This instance of\nthe cache is a wrapper around a CacheLib cache instance and is appropriately\ninstrumented to run several kinds of testing (consistency checking,\ncorrectness validation etc.)"),(0,i.mdx)("p",null,"The main customization points into CacheBench are through writing workload\nconfigs that represent new workloads or  by writing custom workload generators\n(like the piece-wise replay generator)."),(0,i.mdx)("h2",{id:"write-a-new-config"},"Write a new config"),(0,i.mdx)("p",null,"To write a CacheBench config, you must specify the workload configuration\nfirst. The workload configuration describes the nature of the cache workload\nby defining the number of cache objects, their size and popularity\ndistribution, and the distribution of API operations."),(0,i.mdx)("h3",{id:"simple-config-with-key-value-sizes-and-popularity-distribution"},"Simple config with key-value sizes and popularity distribution"),(0,i.mdx)("p",null,"The following config sets up a basic ",(0,i.mdx)("a",{parentName:"p",href:"HybridCache"},"hybrid cache")," instance with two DRAM cache pools and also sets up and runs it in a DRAM-backed mode (useful for testing). The test config itself specifies the number of operations per threads, number of threads, number of keys, and then proceeds to describe the distribution of its key and value sizes and the distribution of the operations. It\u2019s an example of a simple config that is usually written by a person for the purpose of adding a new integration test or a simple benchmark for a particular feature. Configs in this manner are not meant for representing real life workloads and used for performance measurements. For reference on what each option means, please refer to these files."),(0,i.mdx)("ul",null,(0,i.mdx)("li",{parentName:"ul"},"Cache Config: ",(0,i.mdx)("inlineCode",{parentName:"li"},"cachebench/util/CacheConfig.h")),(0,i.mdx)("li",{parentName:"ul"},"Stressor Config: ",(0,i.mdx)("inlineCode",{parentName:"li"},"cachebench/util/Config.h"))),(0,i.mdx)("details",null," ",(0,i.mdx)("summary",null," Sample config  "),(0,i.mdx)("pre",null,(0,i.mdx)("code",{parentName:"pre",className:"language-json"},'{\n  "cache_config" : {\n    "cacheSizeMB" : 128,\n    "poolRebalanceIntervalSec" : 1,\n    "moveOnSlabRelease" : false,\n\n    "numPools" : 2,\n    "poolSizes" : [0.3, 0.7],\n\n    "dipperSizeMB" : 512,\n    "dipperBackend" : "navy_dipper",\n    "enableChainedItem" : true,\n    "dipperUseDirectIO": false,\n    "dipperFilePath" : "/dev/shm/cachebench"\n  },\n  "test_config" :\n    {\n      "prepopulateCache" : true,\n\n      "numOps" : 100000,\n      "numThreads" : 16,\n      "numKeys" : 100000,\n      "distribution" :  "range",\n\n      "keySizeRange" : [1, 8, 64],\n      "keySizeRangeProbability" : [0.3, 0.7],\n\n      "valSizeRange" : [256, 1024, 4096],\n      "valSizeRangeProbability" : [0.2, 0.8],\n\n      "chainedItemLengthRange" : [1, 2, 4, 32],\n      "chainedItemLengthRangeProbability" : [0.8, 0.18, 0.02],\n\n      "chainedItemValSizeRange" : [1, 128, 256, 1024, 4096, 20480],\n      "chainedItemValSizeRangeProbability" : [0.1, 0.1, 0.2, 0.3, 0.3],\n\n      "getRatio" : 0.5,\n      "setRatio" : 0.3,\n      "addChainedRatio" : 0.2,\n      "keyPoolDistribution": [0.5, 0.5],\n      "opPoolDistribution" : [0.5, 0.5]\n    }\n}\n'))),(0,i.mdx)("p",null,"The value size will be changed to max(valSize, sizeof(CacheValue)) when allocate in the cache for cachebench. If the size distribution is important to the test, this may affect the test."),(0,i.mdx)("h3",{id:"real-world-config-example"},"Real world config example"),(0,i.mdx)("p",null,"Coming up with appropriate distribution sizes of key, values and getting their popularity is a challenging problem. To make this easier, CacheBench can take the popularity and size distribution through json files. To examine a real world config at use in production service, refer to ",(0,i.mdx)("inlineCode",{parentName:"p"},"cachelib/cachebench/test_configs/ssd_perf/graph_cache_leader/config.json")),(0,i.mdx)("p",null,"This describes the cache setup (similar to how we do it in the simple test config example above) for a production service. The ",(0,i.mdx)("inlineCode",{parentName:"p"},"pop.json")," file describes the popularity distribution across the key space and the ",(0,i.mdx)("inlineCode",{parentName:"p"},"sizes.json")," file describes the value distribution across the key space. They are key to getting close to simulate a production workload."),(0,i.mdx)("p",null,"These files are generated by our workload analyzer. We currently have the ability to generate workload configs by taking the most recent social graph and general purpose look-aside cache traces. For example to generate a workload config that simulates the most recent two days of traffic, simply run:"),(0,i.mdx)("h3",{id:"replay-production-cache-traces"},"Replay production cache traces"),(0,i.mdx)("p",null,"CacheBench can also be used to replay the production cache traces. This is as close as we can get to production and is very useful when we want to simulate a cache setup that is similar to production. To do that, we need to size our cache to the same scale as our trace. If the trace is sampled at 0.01% of the traffic across 1000 hosts, then we need a cache size that\u2019s roughly 10% of production.  To do this, under the ",(0,i.mdx)("inlineCode",{parentName:"p"},"test_config"),", instead of passing the workload distribution, you can pass the trace file location. To handle the trace file appropriately, see examples in ",(0,i.mdx)("inlineCode",{parentName:"p"},"cachebench/workload/KVReplayGenerator.h")),(0,i.mdx)("details",null," ",(0,i.mdx)("summary",null," Example replay based config file "),(0,i.mdx)("pre",null,(0,i.mdx)("code",{parentName:"pre",className:"language-json"},'{\n  "cache_config": {\n    "cacheSizeMB": 8192,\n    "poolRebalanceIntervalSec": 0\n  },\n  "test_config":\n    {\n      "enableLookaside": true,\n      "generator": "replay",\n      "numOps": 240000000,\n      "numThreads": 1,\n      "prepopulateCache": true,\n      "traceFileName": "cache_trace.csv"\n    }\n\n}\n'))),(0,i.mdx)("p",null,"Due to the size of trace file, we do not store the raw traces in CacheBench repo. So to run the config above, the user must first fetch the raw trace locally and put it in the same directory as the config file."),(0,i.mdx)("p",null,"To handle the trace file format, you can write your own workload generator.\n",(0,i.mdx)("inlineCode",{parentName:"p"},"PiecewiseReplayGenerator")," is one such example replay generator."),(0,i.mdx)("h2",{id:"writing-a-new-workload-generator"},"Writing a new workload generator"),(0,i.mdx)("p",null,"Workload generator needs to implement an interface that CacheBench\u2019s Cache implementation expects. The most important two APIs are as follows."),(0,i.mdx)("pre",null,(0,i.mdx)("code",{parentName:"pre",className:"language-cpp"},"# Get a request for our next operation. The request contains key and size.\nconst Request& getReq(uint8_t poolId, std::mt19937& gen);\n\n# Get an operation to go with the generated request (e.g. get, set, del)\nOpType getOp(uint8_t pid, std::mt19937& gen);\n")),(0,i.mdx)("p",null,"For an example, please look at OnlineGenerator (",(0,i.mdx)("inlineCode",{parentName:"p"},"cachebench/workload/OnlineGenerator.h"),") which implements a generator that use distribution descriptions for popularity and value sizes to generates requests."))}u.isMDXComponent=!0},45964:function(e,n,t){n.Z=t.p+"assets/images/cachebench-25d1d476ed27af8ec3a0b5033571dd1a.png"}}]);